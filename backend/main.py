import os
import math
from datetime import datetime
import pandas as pd
import requests
from fastapi import FastAPI, File, HTTPException, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from processor import processar_excel
from io import BytesIO
from openpyxl import Workbook
from fastapi.encoders import jsonable_encoder
from fastapi.responses import StreamingResponse

# ==========================
# CONFIG SUPABASE
# ==========================

SUPABASE_URL = os.getenv("SUPABASE_URL")
SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

if not SUPABASE_URL:
    raise RuntimeError("‚ö†Ô∏è Defina SUPABASE_URL no .env")

# remover "db." se vier na URL
if "db." in SUPABASE_URL:
    SUPABASE_URL = SUPABASE_URL.replace("db.", "")

if not SERVICE_ROLE_KEY:
    raise RuntimeError("‚ö†Ô∏è Defina SUPABASE_SERVICE_ROLE_KEY no .env")

HEADERS = {
    "apikey": SERVICE_ROLE_KEY,
    "Authorization": f"Bearer {SERVICE_ROLE_KEY}",
    "Content-Type": "application/json",
}

class LimiteAprovadoPayload(BaseModel):
    limite_aprovado: float | None = None
    observacao: str | None = None
    aprovado_por: str | None = None
    class Config:
        extra = "ignore"

# New Pydantic Models for Dashboard Data
class DashboardFiltrosPeriodo(BaseModel):
    min_mes_ref: Optional[str] = None
    max_mes_ref: Optional[str] = None

    class Config:
        extra = "ignore"

class DashboardContext(BaseModel):
    clinica_id: Optional[str] = None
    clinica_nome: Optional[str] = None
    class Config:
        extra = "ignore"

class DashboardKpis(BaseModel):
    score_atual: Optional[float] = None
    score_mes_anterior: Optional[float] = None
    score_variacao_vs_m1: Optional[float] = None
    categoria_risco: Optional[str] = None

    limite_aprovado: Optional[float] = None

    # NOVOS CAMPOS DO PER√çODO FILTRADO
    valor_total_emitido_periodo: Optional[float] = None
    valor_emitido_ultimo_mes: Optional[float] = None

    inadimplencia_media_periodo: Optional[float] = None
    inadimplencia_ultimo_mes: Optional[float] = None

    taxa_pago_no_vencimento_media_periodo: Optional[float] = None
    taxa_pago_no_vencimento_ultimo_mes: Optional[float] = None

    ticket_medio_periodo: Optional[float] = None
    ticket_medio_ultimo_mes: Optional[float] = None

    tempo_medio_pagamento_media_periodo: Optional[float] = None
    tempo_medio_pagamento_ultimo_mes: Optional[float] = None

    # Limite sugerido
    limite_sugerido: Optional[float] = None
    limite_sugerido_base_media12m: Optional[float] = None
    limite_sugerido_base_media3m: Optional[float] = None
    limite_sugerido_base_ultimo_mes: Optional[float] = None
    limite_sugerido_base_mensal_mix: Optional[float] = None
    limite_sugerido_fator: Optional[float] = None
    limite_sugerido_teto_global: Optional[float] = None
    limite_sugerido_share_portfolio_12m: Optional[float] = None
    class Config:
        extra = "ignore"


class DashboardSeries(BaseModel):
    score_por_mes: Optional[List[Dict[str, Any]]] = None
    valor_emitido_por_mes: Optional[List[Dict[str, Any]]] = None
    inadimplencia_por_mes: Optional[List[Dict[str, Any]]] = None
    taxa_pago_no_vencimento_por_mes: Optional[List[Dict[str, Any]]] = None
    tempo_medio_pagamento_por_mes: Optional[List[Dict[str, Any]]] = None
    parcelas_media_por_mes: Optional[List[Dict[str, Any]]] = None
    class Config:
        extra = "ignore"

class DashboardRankingClinicas(BaseModel):
    clinica_id: Optional[str] = None
    clinica_nome: Optional[str] = None
    cnpj: Optional[str] = None
    score_credito: Optional[float] = None
    categoria_risco: Optional[str] = None
    limite_aprovado: Optional[float] = None
    limite_sugerido: Optional[float] = None
    valor_total_emitido_periodo: Optional[float] = None
    inadimplencia_media_periodo: Optional[float] = None
    class Config:
        extra = "ignore"

class DashboardData(BaseModel):
    filtros: Dict[str, DashboardFiltrosPeriodo]
    contexto: DashboardContext
    kpis: DashboardKpis
    series: DashboardSeries
    ranking_clinicas: List[DashboardRankingClinicas]

    class Config:
        extra = "ignore"



# ==========================
# FASTAPI APP
# ==========================

app = FastAPI(title="MedSimples ¬∑ Importa√ß√£o de dados")

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://medsimples-controleodonto.up.railway.app",
        "http://localhost:5173"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def read_root():
    return {"status": "ok"}



# ==========================
# HELPERS SUPABASE
# ==========================


def supabase_post(table: str, data: dict, on_conflict: str | None = None):
    url = f"{SUPABASE_URL}/rest/v1/{table}"
    params = {}
    if on_conflict:
        params["on_conflict"] = on_conflict

    r = requests.post(
        url,
        headers={**HEADERS, "Prefer": "return=representation"},
        params=params,
        json=data,
    )

    if r.status_code not in (200, 201):
        raise RuntimeError(f"Erro ao enviar para {table}: {r.status_code} - {r.text}")

    try:
        return r.json()[0]
    except Exception:
        return None


def supabase_get(table: str, select: str = "*", extra_params: dict | None = None):
    """GET simples no PostgREST, retornando lista de dicts."""
    url = f"{SUPABASE_URL}/rest/v1/{table}"

    params = {"select": select}
    if extra_params:
        params.update(extra_params)

    r = requests.get(url, headers=HEADERS, params=params)

    if r.status_code not in (200, 206):
        raise RuntimeError(f"Erro ao buscar {table}: {r.status_code} - {r.text}")

    return r.json()


def to_df(rows, columns=None):
    if not rows:
        return pd.DataFrame(columns=columns or [])
    df = pd.DataFrame(rows)
    return df


# ==========================
# ENDPOINTS B√ÅSICOS
# ==========================


@app.get("/ping")
def ping():
    return {"status": "ok"}


@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """
    Recebe um arquivo Excel (.xlsx), processa e insere os dados no Supabase.
    """
    try:
        contents = await file.read()
        resultado = processar_excel(contents, arquivo_nome=file.filename)
        return resultado
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao processar o arquivo: {e}",
        )


@app.post("/clinicas/{clinica_id}/limite_aprovado")
async def definir_limite_aprovado(clinica_id: str, payload: LimiteAprovadoPayload):

    if payload.limite_aprovado is None:
        # Registro de revoga√ß√£o
        row = {
            "clinica_id": clinica_id,
            "limite_aprovado": None,
            "observacao": "Limite revogado",
            "aprovado_por": payload.aprovado_por,
        }
    else:
        # Registro de aprova√ß√£o normal
        row = {
            "clinica_id": clinica_id,
            "limite_aprovado": float(payload.limite_aprovado),
            "observacao": payload.observacao or None,
            "aprovado_por": payload.aprovado_por,
        }


    try:
        inserido = supabase_post("clinica_limite", row)
    except RuntimeError as e:
        raise HTTPException(status_code=500, detail=str(e))

    return {"ok": True, "registro": inserido}


@app.get("/clinicas/{clinica_id}/limites")
async def listar_limites_clinica(clinica_id: str):
    """
    Retorna o hist√≥rico de limites aprovados de uma cl√≠nica,
    do mais recente para o mais antigo.
    """
    try:
        rows = supabase_get(
            "clinica_limite",
            select=(
                "limite_aprovado,"
                "faturamento_base,"
                "score_base,"
                "aprovado_em,"
                "aprovado_por,"
                "observacao"
            ),
            extra_params={
                "clinica_id": f"eq.{clinica_id}",
                "order": "aprovado_em.desc",
            },
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao buscar limites da cl√≠nica: {e}",
        )

    return rows




@app.get("/historico")
async def listar_historico():
    """
    Lista o hist√≥rico de importa√ß√µes, j√° juntando com a tabela `clinicas`
    e enriquecendo com:
      - total_registros (espelho de total_linhas)
      - total_boletos_emitidos (soma de qtde da cl√≠nica)
      - total_inadimplencia (m√©dia da taxa de inadimpl√™ncia da cl√≠nica)
    """

    # 1) Buscar importa√ß√µes + cl√≠nica
    try:
        importacoes = supabase_get(
            "importacoes",
            select=(
                "id,clinica_id,arquivo_nome,total_linhas,status,criado_em,"
                "clinicas:clinica_id(id,nome,cnpj,external_id)"
            ),
            extra_params={"order": "criado_em.desc"},
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao buscar hist√≥rico: {e}",
        )

    if not importacoes:
        return []

    # 2) Coletar IDs de cl√≠nica presentes no hist√≥rico
    clinica_ids = sorted(
        {row.get("clinica_id") for row in importacoes if row.get("clinica_id")}
    )

    totais_boletos_por_clinica: dict[str, int] = {}
    media_inadimplencia_por_clinica: dict[str, float] = {}

    if clinica_ids:
        ids_in = ",".join(clinica_ids)

        # 2.1 Boletos emitidos
        try:
            boletos_rows = supabase_get(
                "boletos_emitidos",
                select="clinica_id,qtde",
                extra_params={"clinica_id": f"in.({ids_in})"},
            )
        except Exception:
            boletos_rows = []

        # Agregar boletos (soma)
        for row in boletos_rows or []:
            cid = row.get("clinica_id")
            if not cid:
                continue
            qtde = row.get("qtde") or 0
            try:
                qtde = int(qtde)
            except Exception:
                qtde = 0
            totais_boletos_por_clinica[cid] = (
                totais_boletos_por_clinica.get(cid, 0) + qtde
            )

        # 2.2 Inadimpl√™ncia REAL
        try:
            dash_rows = supabase_get(
                "vw_dashboard_final",
                select="clinica_id,mes_ref_date,valor_total_emitido,taxa_pago_no_vencimento,taxa_inadimplencia",
                extra_params={"clinica_id": f"in.({ids_in})"},
            )
        except Exception:
            dash_rows = []

        df_dash = to_df(dash_rows)

        if not df_dash.empty:
            # Ignorar m√™s atual
            hoje_utc = datetime.utcnow()
            primeiro_dia_mes_atual = hoje_utc.replace(
                day=1, hour=0, minute=0, second=0, microsecond=0
            ).date()
            if "mes_ref_date" in df_dash.columns:
                df_dash["mes_ref_date"] = pd.to_datetime(
                    df_dash["mes_ref_date"], errors="coerce"
                )
                df_dash = df_dash[
                    df_dash["mes_ref_date"].dt.date < primeiro_dia_mes_atual
                ]

            # Tipos num√©ricos e preenchimento de nulos
            for col in [
                "valor_total_emitido",
                "taxa_pago_no_vencimento",
                "taxa_inadimplencia",
            ]:
                if col in df_dash.columns:
                    df_dash[col] = pd.to_numeric(df_dash[col], errors="coerce")

            df_dash = df_dash.fillna(
                {
                    "valor_total_emitido": 0,
                    "taxa_pago_no_vencimento": 0,
                    "taxa_inadimplencia": 0,
                }
            )

            # C√°lculo da inadimpl√™ncia real
            df_dash["taxa_pago_no_vencimento"] = df_dash[
                "taxa_pago_no_vencimento"
            ].clip(0, 1)
            df_dash["taxa_inad_dos_atrasados"] = df_dash["taxa_inadimplencia"].clip(0, 1)
            df_dash["valor_nao_pago_no_venc"] = df_dash["valor_total_emitido"] * (
                1 - df_dash["taxa_pago_no_vencimento"]
            )
            df_dash["valor_inad_real"] = (
                df_dash["valor_nao_pago_no_venc"]
                * df_dash["taxa_inad_dos_atrasados"]
            )

            # Agregar por cl√≠nica (m√©dia ponderada)
            agg_df = df_dash.groupby("clinica_id").agg(
                valor_inad_real_total=("valor_inad_real", "sum"),
                valor_total_emitido_total=("valor_total_emitido", "sum"),
            )

            for cid, row in agg_df.iterrows():
                emitido = row["valor_total_emitido_total"]
                inad = row["valor_inad_real_total"]
                if emitido > 0:
                    media_inadimplencia_por_clinica[str(cid)] = inad / emitido

    # 3) Enriquecer cada registro do hist√≥rico com os totais reais
    historico_enriquecido = []
    for imp in importacoes:
        cid = imp.get("clinica_id")
        imp["total_registros"] = imp.get("total_linhas") or 0
        imp["total_boletos_emitidos"] = totais_boletos_por_clinica.get(cid, 0)
        imp["total_inadimplencia"] = media_inadimplencia_por_clinica.get(cid, 0) or 0
        historico_enriquecido.append(imp)

    return historico_enriquecido


# ==========================
# DASHBOARD ¬∑ RESUMO GERAL
# ==========================


@app.get("/dashboard/resumo-geral")
async def dashboard_resumo_geral():
    """
    Retorna um resumo consolidado para o dashboard interno:
    - total de boletos
    - valor total
    - ticket m√©dio
    - taxa pago no vencimento (√∫ltimo m√™s)
    - inadimpl√™ncia (√∫ltimo m√™s)
    - tempo m√©dio de pagamento (√∫ltimo m√™s)
    - s√©ries por m√™s para gr√°ficos
    """

    try:
        # --- Tabelas base ---
        boletos_rows = supabase_get(
            "boletos_emitidos", select="mes_ref,qtde,valor_total"
        )
        inad_rows = supabase_get("inadimplencia", select="mes_ref,taxa")
        taxa_venc_rows = supabase_get("taxa_pago_no_vencimento", select="mes_ref,taxa")
        tempo_rows = supabase_get("tempo_medio_pagamento", select="mes_ref,dias")
        ticket_rows = supabase_get("valor_medio_boleto", select="mes_ref,valor")
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Erro ao carregar dados do Supabase: {e}"
        )

    # ----------------------
    # DataFrames
    # ----------------------
    df_boletos = to_df(boletos_rows, ["mes_ref", "qtde", "valor_total"])
    df_inad = to_df(inad_rows, ["mes_ref", "taxa"])
    df_taxa_venc = to_df(taxa_venc_rows, ["mes_ref", "taxa"])
    df_tempo = to_df(tempo_rows, ["mes_ref", "dias"])
    df_ticket = to_df(ticket_rows, ["mes_ref", "valor"])

    # Garantir tipos num√©ricos
    if not df_boletos.empty:
        df_boletos["qtde"] = pd.to_numeric(df_boletos["qtde"], errors="coerce").fillna(
            0
        )
        df_boletos["valor_total"] = pd.to_numeric(
            df_boletos.get("valor_total", 0), errors="coerce"
        ).fillna(0)

    if not df_inad.empty:
        df_inad["taxa"] = pd.to_numeric(df_inad["taxa"], errors="coerce").fillna(0)

    if not df_taxa_venc.empty:
        df_taxa_venc["taxa"] = pd.to_numeric(
            df_taxa_venc["taxa"], errors="coerce"
        ).fillna(0)

    if not df_tempo.empty:
        df_tempo["dias"] = pd.to_numeric(df_tempo["dias"], errors="coerce").fillna(0)

    if not df_ticket.empty:
        df_ticket["valor"] = pd.to_numeric(df_ticket["valor"], errors="coerce").fillna(
            0
        )

    # ----------------------
    # KPI gerais
    # ----------------------
    total_boletos = int(df_boletos["qtde"].sum()) if not df_boletos.empty else 0
    valor_total_boletos = (
        float(df_boletos["valor_total"].sum()) if not df_boletos.empty else 0.0
    )
    ticket_medio_global = (
        (valor_total_boletos / total_boletos) if total_boletos > 0 else None
    )

    # √∫ltimo m√™s de refer√™ncia (pelo boletos_emitidos)
    periodo_referencia = None
    if not df_boletos.empty and "mes_ref" in df_boletos.columns:
        df_boletos_sorted = df_boletos.sort_values("mes_ref")
        periodo_referencia = df_boletos_sorted["mes_ref"].iloc[-1]

    # fun√ß√£o helper pra pegar valor do √∫ltimo m√™s de uma df qualquer
    def valor_ultimo_mes(df, coluna_valor):
        if df.empty:
            return None
        try:
            df_sorted = df.sort_values("mes_ref")
            return float(df_sorted[coluna_valor].iloc[-1])
        except Exception:
            return None

    taxa_inad_ultimo = valor_ultimo_mes(df_inad, "taxa")
    taxa_pago_venc_ultimo = valor_ultimo_mes(df_taxa_venc, "taxa")
    tempo_medio_ultimo = valor_ultimo_mes(df_tempo, "dias")
    ticket_medio_ultimo = valor_ultimo_mes(df_ticket, "valor")

    # ----------------------
    # S√©ries por m√™s (pra gr√°fico)
    # ----------------------
    series_boletos = []
    if not df_boletos.empty:
        grp = (
            df_boletos.groupby("mes_ref", as_index=False)[["qtde", "valor_total"]].sum()
        )
        grp = grp.sort_values("mes_ref")
        series_boletos = grp.to_dict(orient="records")

    series_inad = []
    if not df_inad.empty:
        grp = df_inad.groupby("mes_ref", as_index=False)["taxa"].mean().sort_values(
            "mes_ref"
        )
        series_inad = grp.to_dict(orient="records")

    series_taxa_venc = []
    if not df_taxa_venc.empty:
        grp = (
            df_taxa_venc.groupby("mes_ref", as_index=False)["taxa"]
            .mean()
            .sort_values("mes_ref")
        )
        series_taxa_venc = grp.to_dict(orient="records")

    series_tempo = []
    if not df_tempo.empty:
        grp = (
            df_tempo.groupby("mes_ref", as_index=False)["dias"]
            .mean()
            .sort_values("mes_ref")
        )
        series_tempo = grp.to_dict(orient="records")

    return {
        "periodo_referencia": periodo_referencia,
        "kpis": {
            "total_boletos": total_boletos,
            "valor_total_boletos": valor_total_boletos,
            "ticket_medio_global": ticket_medio_global,
            "taxa_inadimplencia_ultimo": taxa_inad_ultimo,
            "taxa_pago_no_vencimento_ultimo": taxa_pago_venc_ultimo,
            "tempo_medio_pagamento_ultimo": tempo_medio_ultimo,
            "ticket_medio_ultimo": ticket_medio_ultimo,
        },
        "series": {
            "boletos_por_mes": series_boletos,
            "inadimplencia_por_mes": series_inad,
            "taxa_pago_no_vencimento": series_taxa_venc,
            "tempo_medio_pagamento": series_tempo,
        },
    }


# ==========================
# DASHBOARD ¬∑ CR√âDITO & RISCO (vw_dashboard_final)
# ==========================

from pandas import Timestamp

def _write_data_to_sheet(ws, data, title=None):
    if title:
        ws.append([title])
        ws.append([]) # Add a blank row for spacing

    if isinstance(data, dict):
        for key, value in data.items():
            ws.append([key, str(value)]) # Write key-value pairs
    elif isinstance(data, list) and data:
        # Assuming list of dictionaries, write header first
        headers = list(data[0].keys())
        ws.append(headers)
        for row_data in data:
            ws.append([row_data.get(header, "") for header in headers])
    ws.append([]) # Add a blank row after each section


def _safe_float(v):
    try:
        if v is None:
            return None
        f = float(v)
        if pd.isna(f):
            return None
        return float(f)
    except Exception:
        return None


def _safe_str(v):
    if v is None:
        return None
    return str(v)


def _format_mes_ref(dt: Timestamp | None):
    if dt is None or pd.isna(dt):
        return None
    try:
        return dt.strftime("%Y-%m")
    except Exception:
        return None
    

# ==========================
# FUN√á√ÉO AUXILIAR ‚Äî √öLTIMO M√äS FECHADO
# ==========================
def identificar_ultimo_mes_fechado(df_importacoes, clinica_id):
    """
    Retorna o √∫ltimo m√™s realmente fechado para uma cl√≠nica com base
    na data de importa√ß√£o.
    """
    df = df_importacoes[df_importacoes["clinica_id"] == clinica_id].copy()
    if df.empty:
        return None

    df["criado_em"] = pd.to_datetime(df["criado_em"], errors="coerce")
    df["mes_ref_date"] = pd.to_datetime(
        df["mes_ref"].astype(str) + "-01",
        errors="coerce"
    )

    df.dropna(subset=["criado_em", "mes_ref_date"], inplace=True)
    
    if df.empty:
        return None

    # M√™s est√° fechado se foi importado ap√≥s o fim do pr√≥prio m√™s
    end_of_month = df["mes_ref_date"] + pd.offsets.MonthEnd(0)
    df["fechado"] = df["criado_em"].dt.date >= (end_of_month + pd.Timedelta(days=1)).dt.date

    df_fechado = df[df["fechado"] == True]
    if df_fechado.empty:
        return None

    return df_fechado["mes_ref_date"].max()


@app.get("/dashboard/clinicas")
async def listar_clinicas_dashboard():
    """
    Lista cl√≠nicas presentes na view `vw_dashboard_final`
    para uso no filtro do dashboard de cr√©dito & risco.
    """
    try:
        rows = supabase_get(
            "vw_dashboard_final",
            select="clinica_id,clinica_nome,cnpj,external_id",
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao carregar cl√≠nicas do dashboard: {e}",
        )

    df = to_df(
        rows,
        columns=["clinica_id", "clinica_nome", "cnpj", "external_id"],
    )

    if df.empty:
        return []

    df = df.drop_duplicates(subset=["clinica_id"])

    clinicas = []
    for _, row in df.iterrows():
        clinicas.append(
            {
                "id": _safe_str(row.get("clinica_id")),
                "nome": _safe_str(row.get("clinica_nome"))
                or _safe_str(row.get("external_id"))
                or _safe_str(row.get("cnpj")),
                "cnpj": _safe_str(row.get("cnpj")),
                "external_id": _safe_str(row.get("external_id")),
            }
        )

    clinicas = sorted(clinicas, key=lambda x: (x["nome"] or "").lower())
    return clinicas


def _fator_limite_score(s):
    s = _safe_float(s)
    if s is None:
        return 0.15
    if s >= 0.80:
        return 0.90
    if s >= 0.70:
        return 0.75
    if s >= 0.60:
        return 0.60
    if s >= 0.50:
        return 0.45
    if s >= 0.40:
        return 0.35
    if s >= 0.20:
        return 0.25
    return 0.15

def _clamp01(x):
    try:
        x = float(x)
    except Exception:
        return 0.0
    if math.isnan(x):
        return 0.0
    return max(0.0, min(1.0, x))

def _calc_score_row(row):
    inad_real = row.get("taxa_inadimplencia_real")
    pago_venc = row.get("taxa_pago_no_vencimento")
    dias = row.get("tempo_medio_pagamento_dias")
    parc = row.get("parc_media_parcelas_pond")
    risk_inad = _clamp01(inad_real / 0.03) if inad_real is not None else 0.0
    risk_atraso = _clamp01((1.0 - float(pago_venc)) / 0.25) if pago_venc is not None else 0.0
    risk_dias = _clamp01((float(dias) - 5.0) / 60.0) if dias is not None else 0.0
    risk_parc = _clamp01((float(parc) - 1.0) / 11.0) if parc is not None else 0.0
    score = 1.0 - (0.50 * risk_inad + 0.25 * risk_atraso + 0.15 * risk_dias + 0.10 * risk_parc)
    return max(0.0, min(1.0, score))

def _categoria_from_score(s):
    s = _safe_float(s)
    if s is None: return None
    if s >= 0.80: return "A"
    if s >= 0.60: return "B"
    if s >= 0.40: return "C"
    if s >= 0.20: return "D"
    return "E"

@app.get("/dashboard", response_model=DashboardData)
async def dashboard_completo(
    clinica_id: str | None = None,
    meses: int = 12,
    inicio: str | None = None,
    fim: str | None = None,
    mes_ref_custom: str | None = None,  # üëà novo par√¢metro!
):
    """
    Dashboard completo de CR√âDITO & RISCO usando `vw_dashboard_final`.

    - Se `clinica_id` vier preenchido, o contexto √© aquela cl√≠nica.
    - Se n√£o vier, o contexto √© "Todas as cl√≠nicas" (vis√£o agregada).

    Regras importantes:
    - Ignora sempre o m√™s em aberto (m√™s atual).
    - Calcula inadimpl√™ncia REAL (sobre o total emitido).
    - Calcula um SCORE AJUSTADO e categoria A‚ÄìE.
    - Calcula um LIMITE SUGERIDO conservador por cl√≠nica (quando clinica_id √© enviado)
      usando a m√©dia dos √∫ltimos 12 meses, 3 meses, √∫ltimo m√™s e o score.
    """
    try:
        # --------------------------
        # 1) Carregar dados da view
        # --------------------------
        extra = {}
        try:
            rows = supabase_get("vw_dashboard_final", select="*", extra_params=extra)
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Erro ao carregar dados do dashboard: {e}",
            )

        df = to_df(rows)

        if df.empty:
            return {
                "filtros": {"periodo": {"min_mes_ref": None, "max_mes_ref": None}},
                "contexto": {
                    "clinica_id": clinica_id,
                    "clinica_nome": "Sem dados",
                },
                "kpis": {},
                "series": {},
                "ranking_clinicas": [],
            }

        # --------------------------
        # 2) Preparar datas
        # --------------------------
        if "mes_ref_date" in df.columns:
            df["mes_ref_date"] = pd.to_datetime(df["mes_ref_date"], errors="coerce")
        else:
            df["mes_ref_date"] = pd.to_datetime(df["mes_ref"], errors="coerce")

        df = df.dropna(subset=["mes_ref_date"])

        # Ignorar sempre o m√™s em aberto (m√™s atual)
        hoje_utc = datetime.utcnow()
        primeiro_dia_mes_atual = hoje_utc.replace(day=1, hour=0, minute=0, second=0, microsecond=0).date()
        df = df[df["mes_ref_date"].dt.date < primeiro_dia_mes_atual]

        if df.empty:
            return {
                "filtros": {"periodo": {"min_mes_ref": None, "max_mes_ref": None}},
                "contexto": {
                    "clinica_id": clinica_id,
                    "clinica_nome": "Sem dados v√°lidos (m√™s em aberto ignorado)",
                },
                "kpis": {},
                "series": {},
                "ranking_clinicas": [],
            }

        # --------------------------
        # 3) Tipos num√©ricos
        # --------------------------
        def _num(col, fill=None):
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
                if fill is not None:
                    df[col] = df[col].fillna(fill)

        _num("valor_total_emitido", fill=0)
        _num("taxa_pago_no_vencimento")
        _num("taxa_inadimplencia")
        _num("tempo_medio_pagamento_dias")
        _num("parc_media_parcelas_pond")
        _num("valor_medio_boleto")
        _num("limite_aprovado")

        # --------------------------
        # 4) Inadimpl√™ncia REAL
        # --------------------------
        if "taxa_pago_no_vencimento" not in df.columns:
            df["taxa_pago_no_vencimento"] = 0.0
        if "taxa_inadimplencia" not in df.columns:
            df["taxa_inadimplencia"] = 0.0

        df["taxa_pago_no_vencimento"] = df["taxa_pago_no_vencimento"].clip(0, 1)
        df["taxa_inad_dos_atrasados"] = df["taxa_inadimplencia"].clip(0, 1)

        df["valor_nao_pago_no_venc"] = df["valor_total_emitido"] * (
            1 - df["taxa_pago_no_vencimento"]
        )
        df["valor_inad_real"] = df["valor_nao_pago_no_venc"] * df["taxa_inad_dos_atrasados"]

        df["taxa_inadimplencia_real"] = None
        mask_emitido = df["valor_total_emitido"] > 0
        df.loc[mask_emitido, "taxa_inadimplencia_real"] = (
            df.loc[mask_emitido, "valor_inad_real"] / df.loc[mask_emitido, "valor_total_emitido"]
        )

        # --------------------------
        # 5) SCORE AJUSTADO
        # --------------------------
        def _clamp01(x):
            try:
                x = float(x)
            except Exception:
                return 0.0
            if math.isnan(x):
                return 0.0
            return max(0.0, min(1.0, x))

        def _calc_score_row(row):
            inad_real = row.get("taxa_inadimplencia_real")  # sobre o total emitido
            pago_venc = row.get("taxa_pago_no_vencimento")  # 0‚Äì1
            dias = row.get("tempo_medio_pagamento_dias")
            parc = row.get("parc_media_parcelas_pond")

            # 1) Risco de inadimpl√™ncia real (0 ‚Üí 0%, 1 ‚Üí 3%+)
            risk_inad = 0.0
            if inad_real is not None:
                risk_inad = _clamp01(inad_real / 0.03)  # 3% vira risco 1

            # 2) Risco de atraso (0 ‚Üí 100% pago no venc., 1 ‚Üí 25%+ fora do venc.)
            risk_atraso = 0.0
            if pago_venc is not None:
                risk_atraso = _clamp01((1.0 - float(pago_venc)) / 0.25)

            # 3) Risco de prazo (0 ‚Üí 5 dias, 1 ‚Üí 65 dias+)
            risk_dias = 0.0
            if dias is not None:
                risk_dias = _clamp01((float(dias) - 5.0) / 60.0)

            # 4) Risco de parcelamento (0 ‚Üí 1 parcela, 1 ‚Üí 12 parcelas+)
            risk_parc = 0.0
            if parc is not None:
                risk_parc = _clamp01((float(parc) - 1.0) / 11.0)

            # Pesos conservadores:
            # inad 50%, atraso 25%, dias 15%, parcelas 10%
            score = 1.0 - (
                0.50 * risk_inad
                + 0.25 * risk_atraso
                + 0.15 * risk_dias
                + 0.10 * risk_parc
            )

            return max(0.0, min(1.0, score))

        df["score_ajustado"] = df.apply(_calc_score_row, axis=1)

        def _categoria_from_score(s):
            s = _safe_float(s)
            if s is None:
                return None
            if s >= 0.80:
                return "A"
            if s >= 0.60:
                return "B"
            if s >= 0.40:
                return "C"
            if s >= 0.20:
                return "D"
            return "E"

        df["categoria_risco_ajustada"] = df["score_ajustado"].apply(_categoria_from_score)

        # --------------------------
        # 6) Per√≠odo global
        # --------------------------
        min_dt = df["mes_ref_date"].min()
        max_dt = df["mes_ref_date"].max()

        limite_inferior_default = max_dt - pd.DateOffset(months=meses - 1)

        # --------------------------
        # 7) Recorte de tempo
        # --------------------------
        if inicio and fim:
            try:
                dt_inicio = pd.to_datetime(inicio + "-01")
                dt_fim = pd.to_datetime(fim + "-01") + pd.offsets.MonthEnd(0)
                df_recorte = df[
                    (df["mes_ref_date"] >= dt_inicio)
                    & (df["mes_ref_date"] <= dt_fim)
                ].copy()
            except Exception as e:
                raise HTTPException(
                    status_code=400,
                    detail=f"Par√¢metros inicio/fim inv√°lidos: {e}",
                )
        else:
            df_recorte = df[df["mes_ref_date"] >= limite_inferior_default].copy()

        # --------------------------
        # 8) Contexto (cl√≠nica x geral)
        # --------------------------
        if clinica_id:
            nomes = (
                df[df["clinica_id"] == clinica_id]["clinica_nome"]
                .dropna()
                .unique()
                .tolist()
            )
            nome_clinica = nomes[0] if nomes else "Cl√≠nica selecionada"
        else:
            nome_clinica = "Todas as cl√≠nicas"

        if clinica_id:
            df_ctx = df_recorte[df_recorte["clinica_id"] == clinica_id].copy()
        else:
            df_ctx = df_recorte.copy()

        if df_ctx.empty:
            return {
                "filtros": {
                    "periodo": {
                        "min_mes_ref": _format_mes_ref(min_dt),
                        "max_mes_ref": _format_mes_ref(max_dt),
                    }
                },
                "contexto": {
                    "clinica_id": clinica_id,
                    "clinica_nome": nome_clinica,
                },
                "kpis": {},
                "series": {},
                "ranking_clinicas": [],
            }

        max_ctx_dt = df_ctx["mes_ref_date"].max()
        df_ctx_ultimo = df_ctx[df_ctx["mes_ref_date"] == max_ctx_dt]

        # helpers
        def mean_col(col):
            if col not in df_ctx.columns:
                return None
            return _safe_float(df_ctx[col].mean())

        def sum_col(col):
            if col not in df_ctx.columns:
                return None
            return _safe_float(df_ctx[col].sum())

        def weighted_avg(df, value_col, weight_col):
            if value_col not in df.columns or weight_col not in df.columns:
                return None
            df_temp = df[[value_col, weight_col]].dropna()
            if df_temp.empty:
                return None
            
            pesos = df_temp[weight_col]
            if pesos.sum() <= 0:
                # Fallback to simple mean if weights are zero/negative
                return df_temp[value_col].mean()
            
            weighted_sum = (df_temp[value_col] * pesos).sum()
            return weighted_sum / pesos.sum()

        # --------------------------
        # 9) KPI principais ‚Äî agora 100% com base no PER√çODO FILTRADO (df_ctx)
        # --------------------------

        # Score atual (m√™s mais recente dentro do per√≠odo)
        col_score = "score_ajustado"

        score_atual = (
            _safe_float(df_ctx_ultimo[col_score].mean())
            if col_score in df_ctx_ultimo.columns
            else None
        )

        # Score m√™s anterior (dentro do per√≠odo filtrado)
        mes_anterior_dt = max_ctx_dt - pd.DateOffset(months=1)
        df_ctx_m1 = df_ctx[df_ctx["mes_ref_date"] == mes_anterior_dt]

        score_mes_anterior = (
            _safe_float(df_ctx_m1[col_score].mean())
            if not df_ctx_m1.empty and col_score in df_ctx_m1.columns
            else None
        )

        score_variacao_vs_m1 = None
        if score_atual is not None and score_mes_anterior is not None:
            score_variacao_vs_m1 = _safe_float(score_atual - score_mes_anterior)

        # Categoria (apenas m√™s atual do per√≠odo)
        categoria_risco = None
        col_cat = "categoria_risco_ajustada"
        if col_cat in df_ctx_ultimo.columns:
            categorias = df_ctx_ultimo[col_cat].dropna().astype(str).unique().tolist()
            categoria_risco = categorias[0] if categorias else None

        # Limite aprovado (continua igual)
        limite_aprovado = (
            _safe_float(df_ctx_ultimo["limite_aprovado"].mean())
            if "limite_aprovado" in df_ctx_ultimo.columns
            else None
        )

        # VALOR EMITIDO NO PER√çODO FILTRADO (SOMA)
        valor_total_emitido_periodo = (
            _safe_float(df_ctx["valor_total_emitido"].sum())
            if "valor_total_emitido" in df_ctx.columns
            else None
        )

        # VALOR EMITIDO DO √öLTIMO M√äS DO PER√çODO
        valor_emitido_ultimo_mes = (
            _safe_float(df_ctx_ultimo["valor_total_emitido"].sum())
            if "valor_total_emitido" in df_ctx_ultimo.columns
            else None
        )

        # INADIMPL√äNCIA REAL NO PER√çODO (m√©dia ponderada sobre o per√≠odo filtrado)
        inad_media_periodo = None
        if "valor_total_emitido" in df_ctx.columns and "valor_inad_real" in df_ctx.columns:
            total_emit = _safe_float(df_ctx["valor_total_emitido"].sum())
            total_inad = _safe_float(df_ctx["valor_inad_real"].sum())

            if total_emit and total_emit > 0 and total_inad is not None:
                inad_media_periodo = total_inad / total_emit

        # INADIMPL√äNCIA REAL DO √öLTIMO M√äS DO PER√çODO
        inad_ultimo_mes = None
        if (
            "valor_total_emitido" in df_ctx_ultimo.columns
            and "valor_inad_real" in df_ctx_ultimo.columns
        ):
            emit_ult = _safe_float(df_ctx_ultimo["valor_total_emitido"].sum())
            inad_ult = _safe_float(df_ctx_ultimo["valor_inad_real"].sum())
            if emit_ult and emit_ult > 0 and inad_ult is not None:
                inad_ultimo_mes = inad_ult / emit_ult

            # TAXA PAGA NO VENCIMENTO ‚Äî per√≠odo filtrado
            pago_venc_media_periodo = _safe_float(weighted_avg(df_ctx, "taxa_pago_no_vencimento", "valor_total_emitido"))
            pago_venc_ultimo_mes = _safe_float(weighted_avg(df_ctx_ultimo, "taxa_pago_no_vencimento", "valor_total_emitido"))
        
        
            # TICKET M√âDIO ‚Äî per√≠odo filtrado
            ticket_medio_periodo = _safe_float(weighted_avg(df_ctx, "valor_medio_boleto", "valor_total_emitido"))
            ticket_medio_ultimo_mes = _safe_float(weighted_avg(df_ctx_ultimo, "valor_medio_boleto", "valor_total_emitido"))
        
        
            # TEMPO M√âDIO ‚Äî per√≠odo filtrado
            tempo_medio_periodo = _safe_float(weighted_avg(df_ctx, "tempo_medio_pagamento_dias", "valor_total_emitido"))
            tempo_medio_ultimo_mes = _safe_float(weighted_avg(df_ctx_ultimo, "tempo_medio_pagamento_dias", "valor_total_emitido"))
        
        
            # PARCELAS M√âDIAS ‚Äî per√≠odo filtrado
            parcelas_media_periodo = _safe_float(weighted_avg(df_ctx, "parc_media_parcelas_pond", "valor_total_emitido"))
            parcelas_media_ultimo_mes = _safe_float(weighted_avg(df_ctx_ultimo, "parc_media_parcelas_pond", "valor_total_emitido"))

        # --------------------------
        # 10) LIMITE SUGERIDO (conservador)
        # --------------------------
        limite_sugerido = None
        limite_sugerido_base_media12m = None
        limite_sugerido_base_media3m = None
        limite_sugerido_base_ultimo_mes = None
        limite_sugerido_base_mensal_mix = None
        limite_sugerido_fator = None
        limite_sugerido_share_portfolio_12m = None

        LIMITE_TETO_GLOBAL = 3_000_000.0  # teto duro por cl√≠nica (ajust√°vel)

        if clinica_id:
            df_clin_all = df[df["clinica_id"] == clinica_id].copy()

            if not df_clin_all.empty:
                # Buscar hist√≥rico de importa√ß√µes
                import_rows = supabase_get(
                    "importacoes",
                    select="clinica_id, criado_em, mes_ref",
                    extra_params={"clinica_id": f"eq.{clinica_id}"}
                )
                df_import = to_df(import_rows)

                # Identificar o √∫ltimo m√™s realmente fechado
                ultimo_mes_fechado = identificar_ultimo_mes_fechado(df_import, clinica_id)

                # Se n√£o houver m√™s fechado, usa o mais recente mesmo
                if ultimo_mes_fechado is None:
                    last_dt_clin = df_clin_all["mes_ref_date"].max()
                else:
                    last_dt_clin = ultimo_mes_fechado

                # üëá override opcional pelo par√¢metro mes_ref_custom (AAAA-MM)
                if mes_ref_custom:
                    try:
                        last_dt_clin = pd.to_datetime(str(mes_ref_custom) + "-01", errors="raise")
                    except Exception:
                        print("‚ö†Ô∏è mes_ref_custom inv√°lido:", mes_ref_custom)
                        # mant√©m last_dt_clin original se estiver inv√°lido


                # 10.1 Janela 12M da cl√≠nica
                dt_inicio_12m_clin = last_dt_clin - pd.DateOffset(months=11)
                df_clin_12m = df_clin_all[
                    df_clin_all["mes_ref_date"] >= dt_inicio_12m_clin
                ].copy()
                if df_clin_12m.empty:
                    df_clin_12m = df_clin_all.copy()

                total_emit_12m_clin = _safe_float(df_clin_12m["valor_total_emitido"].sum())
                n_meses_12m_clin = int(df_clin_12m["mes_ref_date"].nunique() or 0)

                if n_meses_12m_clin > 0 and total_emit_12m_clin is not None:
                    limite_sugerido_base_media12m = total_emit_12m_clin / n_meses_12m_clin

                # 10.2 Janela 3M da cl√≠nica
                dt_inicio_3m = last_dt_clin - pd.DateOffset(months=2)
                df_last3 = df_clin_all[
                    (df_clin_all["mes_ref_date"] >= dt_inicio_3m)
                    & (df_clin_all["mes_ref_date"] <= last_dt_clin)
                ].copy()
                if not df_last3.empty:
                    limite_sugerido_base_media3m = _safe_float(
                        df_last3["valor_total_emitido"].mean()
                    )

                # 10.3 √öltimo m√™s da cl√≠nica
                df_ultimo_mes_clin = df_clin_all[
                    df_clin_all["mes_ref_date"] == last_dt_clin
                ].copy()
                if not df_ultimo_mes_clin.empty:
                    limite_sugerido_base_ultimo_mes = _safe_float(
                        df_ultimo_mes_clin["valor_total_emitido"].sum()
                    )

                # 10.4 Base mensal combinada (12M, 3M, √∫ltimo m√™s)
                componentes = []
                pesos = []

                if limite_sugerido_base_media12m is not None:
                    componentes.append(limite_sugerido_base_media12m)
                    pesos.append(0.50)
                if limite_sugerido_base_media3m is not None:
                    componentes.append(limite_sugerido_base_media3m)
                    pesos.append(0.30)
                if limite_sugerido_base_ultimo_mes is not None:
                    componentes.append(limite_sugerido_base_ultimo_mes)
                    pesos.append(0.20)

                if componentes and sum(pesos) > 0:
                    limite_sugerido_base_mensal_mix = sum(
                        c * p for c, p in zip(componentes, pesos)
                    ) / sum(pesos)
                else:
                    limite_sugerido_base_mensal_mix = None

                # 10.5 Share da cl√≠nica na carteira (12M)
                dt_inicio_12m_share = last_dt_clin - pd.DateOffset(months=11)
                df_port_12m = df[df["mes_ref_date"] >= dt_inicio_12m_share].copy()
                if not df_port_12m.empty and total_emit_12m_clin is not None:
                    total_emit_portfolio_12m = _safe_float(
                        df_port_12m["valor_total_emitido"].sum()
                    )
                    if total_emit_portfolio_12m and total_emit_portfolio_12m > 0:
                        limite_sugerido_share_portfolio_12m = _safe_float(
                            total_emit_12m_clin / total_emit_portfolio_12m
                        )

                # üî• Usa o score do √∫ltimo m√™s da CL√çNICA, n√£o do per√≠odo filtrado
                score_para_limite = _safe_float(df_ultimo_mes_clin["score_ajustado"].mean())
                limite_sugerido_fator = _fator_limite_score(score_para_limite)

                base_para_limite = limite_sugerido_base_mensal_mix or 0.0
                bruto = base_para_limite * (limite_sugerido_fator or 0.0)

                if bruto and bruto > 0:
                    # Nova trava de seguran√ßa: 150% do MAIOR faturamento base (1M, 3M, 12M)
                    bases_validas = [
                        b for b in [
                            limite_sugerido_base_media12m,
                            limite_sugerido_base_media3m,
                            limite_sugerido_base_ultimo_mes
                        ] if b is not None and b > 0
                    ]
                    maior_base = max(bases_validas) if bases_validas else 0
                    teto_dinamico = 1.5 * maior_base

                    limite_sugerido = min(bruto, teto_dinamico, LIMITE_TETO_GLOBAL)
                else:
                    limite_sugerido = None

        # --------------------------
        # 11) S√©ries temporais
        # --------------------------
        grp = df_ctx.groupby("mes_ref_date", as_index=False).agg(
            {
                "score_ajustado": "mean",
                "valor_total_emitido": "sum",
                "valor_inad_real": "sum",
                "taxa_pago_no_vencimento": "mean",
                "tempo_medio_pagamento_dias": "mean",
                "parc_media_parcelas_pond": "mean",
            }
        )

        grp = grp.sort_values("mes_ref_date")

        series_score = []
        series_valor = []
        series_inad = []
        series_pago_venc = []
        series_tempo = []
        series_parc = []

        for _, row in grp.iterrows():
            mes_str = _format_mes_ref(row["mes_ref_date"])

            score_val = _safe_float(row.get("score_ajustado"))
            valor_emitido = _safe_float(row.get("valor_total_emitido"))
            inad_valor = _safe_float(row.get("valor_inad_real"))
            pago_venc_val = _safe_float(row.get("taxa_pago_no_vencimento"))
            tempo_val = _safe_float(row.get("tempo_medio_pagamento_dias"))
            parc_val = _safe_float(row.get("parc_media_parcelas_pond"))

            taxa_inad_mes = None
            if valor_emitido and valor_emitido > 0 and inad_valor is not None:
                taxa_inad_mes = _safe_float(inad_valor / valor_emitido)

            series_score.append(
                {
                    "mes_ref": mes_str,
                    "score_credito": score_val,
                }
            )
            series_valor.append(
                {
                    "clinica_id": row.get("clinica_id"),
                    "mes_ref": mes_str,
                    "valor_total_emitido": valor_emitido,
                    "valor_medio_boleto": row.get("valor_medio_boleto"),
                    "qtde_boletos": row.get("qtde_boletos"),  # se existir na view
                }
            )

            series_inad.append(
                {
                    "mes_ref": mes_str,
                    "taxa_inadimplencia": taxa_inad_mes,
                }
            )
            series_pago_venc.append(
                {
                    "mes_ref": mes_str,
                    "taxa_pago_no_vencimento": pago_venc_val,
                }
            )
            series_tempo.append(
                {
                    "mes_ref": mes_str,
                    "tempo_medio_pagamento_dias": tempo_val,
                }
            )
            series_parc.append(
                {
                    "mes_ref": mes_str,
                    "media_parcelas_pond": parc_val,
                }
            )

        # --------------------------
        # 12) Ranking de cl√≠nicas (√∫ltimo m√™s fechado global)
        # --------------------------
        df_ultimo_global = df[df["mes_ref_date"] == max_dt].copy()

        ranking = []
        if not df_ultimo_global.empty:
            # Usa o recorte de tempo do filtro para os dados da carteira
            agg_periodo_por_clinica = (
                df_recorte.groupby("clinica_id", as_index=False).agg(
                    {
                        "valor_total_emitido": "sum",
                        "valor_inad_real": "sum",
                    }
                )
            )

            def _calc_inad_med(row):
                emit = _safe_float(row.get("valor_total_emitido"))
                inad = _safe_float(row.get("valor_inad_real"))
                if emit and emit > 0 and inad is not None:
                    return _safe_float(inad / emit)
                return None

            agg_periodo_por_clinica["inadimplencia_media_periodo"] = agg_periodo_por_clinica.apply(
                _calc_inad_med, axis=1
            )

            agg_periodo_por_clinica = agg_periodo_por_clinica.rename(
                columns={
                    "valor_total_emitido": "valor_total_emitido_periodo",
                }
            )

            df_rank = df_ultimo_global.merge(
                agg_periodo_por_clinica, on="clinica_id", how="left"
            )

            for _, row in df_rank.iterrows():
                current_clinica_id = _safe_str(row.get("clinica_id"))
                
                # --- C√°lculo do Limite Sugerido para esta cl√≠nica ---
                limite_sugerido_para_clinica = None
                df_clin_all = df[df["clinica_id"] == current_clinica_id].copy()
                if not df_clin_all.empty:
                    last_dt_clin = df_clin_all["mes_ref_date"].max()

                    # Bases de faturamento (12M, 3M, 1M)
                    dt_inicio_12m_clin = last_dt_clin - pd.DateOffset(months=11)
                    df_clin_12m = df_clin_all[df_clin_all["mes_ref_date"] >= dt_inicio_12m_clin].copy()
                    total_emit_12m_clin = _safe_float(df_clin_12m["valor_total_emitido"].sum())
                    n_meses_12m_clin = int(df_clin_12m["mes_ref_date"].nunique() or 0)
                    base_media12m = total_emit_12m_clin / n_meses_12m_clin if n_meses_12m_clin > 0 and total_emit_12m_clin is not None else None

                    dt_inicio_3m = last_dt_clin - pd.DateOffset(months=2)
                    df_last3 = df_clin_all[(df_clin_all["mes_ref_date"] >= dt_inicio_3m) & (df_clin_all["mes_ref_date"] <= last_dt_clin)].copy()
                    base_media3m = _safe_float(df_last3["valor_total_emitido"].mean()) if not df_last3.empty else None

                    df_ultimo_mes_clin = df_clin_all[df_clin_all["mes_ref_date"] == last_dt_clin].copy()
                    base_ultimo_mes = _safe_float(df_ultimo_mes_clin["valor_total_emitido"].sum()) if not df_ultimo_mes_clin.empty else None

                    componentes = []
                    pesos = []
                    if base_media12m is not None: componentes.append(base_media12m); pesos.append(0.50)
                    if base_media3m is not None: componentes.append(base_media3m); pesos.append(0.30)
                    if base_ultimo_mes is not None: componentes.append(base_ultimo_mes); pesos.append(0.20)
                    base_mensal_mix = sum(c * p for c, p in zip(componentes, pesos)) / sum(pesos) if componentes and sum(pesos) > 0 else None

                    score_para_limite = _safe_float(df_ultimo_mes_clin["score_ajustado"].mean())
                    fator = _fator_limite_score(score_para_limite)

                    base_para_limite = base_mensal_mix or 0.0
                    bruto = base_para_limite * (fator or 0.0)

                    if bruto and bruto > 0:
                        bases_validas = [b for b in [base_media12m, base_media3m, base_ultimo_mes] if b is not None and b > 0]
                        maior_base = max(bases_validas) if bases_validas else 0
                        teto_dinamico = 1.5 * maior_base
                        limite_sugerido_para_clinica = min(bruto, teto_dinamico, LIMITE_TETO_GLOBAL)
                # --- Fim do c√°lculo ---

                ranking.append({
                    "clinica_id": current_clinica_id,
                    "clinica_nome": _safe_str(row.get("clinica_nome")),
                    "cnpj": _safe_str(row.get("cnpj")),
                    "score_credito": _safe_float(row.get("score_ajustado")),
                    "categoria_risco": _safe_str(row.get("categoria_risco_ajustada")),
                    "limite_aprovado": _safe_float(row.get("limite_aprovado")),
                    "limite_sugerido": limite_sugerido_para_clinica,
                    "valor_total_emitido_periodo": _safe_float(row.get("valor_total_emitido_periodo")),
                    "inadimplencia_media_periodo": _safe_float(row.get("inadimplencia_media_periodo")),

                    # ‚≠ê ADICIONE ESTA LINHA AQUI ‚≠ê
                    "ticket_medio_periodo": _safe_float(row.get("valor_medio_boleto")), 
                })


            ranking = sorted(
                ranking,
                key=lambda x: (x["score_credito"] or 0),
                reverse=True,
            )

        # --------------------------
        # 13) Montar resposta
        # --------------------------
        response_data = {
            "filtros": {
                "periodo": {
                    "min_mes_ref": _format_mes_ref(min_dt),
                    "max_mes_ref": _format_mes_ref(max_dt),
                    "todos_meses": sorted(
                        {_format_mes_ref(m) for m in df["mes_ref_date"].unique() if m is not None}
                    )
                }
            },
            "contexto": {
                "clinica_id": clinica_id,
                "clinica_nome": nome_clinica,
            },
            "kpis": {
                "score_atual": score_atual,
                "score_mes_anterior": score_mes_anterior,
                "score_variacao_vs_m1": score_variacao_vs_m1,
                "categoria_risco": categoria_risco,

                # Limite aprovado continua igual
                "limite_aprovado": limite_aprovado,

                # KPIs do per√≠odo filtrado
                "valor_total_emitido_periodo": valor_total_emitido_periodo,
                "valor_emitido_ultimo_mes": valor_emitido_ultimo_mes,

                "inadimplencia_media_periodo": inad_media_periodo,
                "inadimplencia_ultimo_mes": inad_ultimo_mes,

                "taxa_pago_no_vencimento_media_periodo": pago_venc_media_periodo,
                "taxa_pago_no_vencimento_ultimo_mes": pago_venc_ultimo_mes,

                "ticket_medio_periodo": ticket_medio_periodo,
                "ticket_medio_ultimo_mes": ticket_medio_ultimo_mes,

                "tempo_medio_pagamento_media_periodo": tempo_medio_periodo,
                "tempo_medio_pagamento_ultimo_mes": tempo_medio_ultimo_mes,

                "parcelas_media_periodo": parcelas_media_periodo,
                "parcelas_media_ultimo_mes": parcelas_media_ultimo_mes,

                # limite sugerido (mantido, n√£o depende do filtro)
                "limite_sugerido": limite_sugerido,
                "limite_sugerido_base_media12m": limite_sugerido_base_media12m,
                "limite_sugerido_base_media3m": limite_sugerido_base_media3m,
                "limite_sugerido_base_ultimo_mes": limite_sugerido_base_ultimo_mes,
                "limite_sugerido_base_mensal_mix": limite_sugerido_base_mensal_mix,
                "limite_sugerido_fator": limite_sugerido_fator,
                "limite_sugerido_teto_global": LIMITE_TETO_GLOBAL,
                "limite_sugerido_share_portfolio_12m": limite_sugerido_share_portfolio_12m,
            },
            "series": {
                "score_por_mes": series_score,
                "valor_emitido_por_mes": series_valor,
                "inadimplencia_por_mes": series_inad,
                "taxa_pago_no_vencimento_por_mes": series_pago_venc,
                "tempo_medio_pagamento_por_mes": series_tempo,
                "parcelas_media_por_mes": series_parc,
            },
            "ranking_clinicas": ranking,
        }
        return jsonable_encoder(response_data)
    except Exception as e:
        import traceback
        print(f"!!! Erro Inesperado no Endpoint /dashboard para clinica_id={clinica_id} !!!")
        print(f"Erro: {e}")
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Ocorreu um erro inesperado ao processar os dados do dashboard: {e}",
        )

# ==========================
# DASHBOARD ¬∑ QUALIDADE DOS DADOS
# ==========================

class InconsistenciaItem(BaseModel):
    tipo: str
    detalhe: str
    mes_ref: Optional[str] = None

class QualidadeClinica(BaseModel):
    clinica_id: str
    clinica_nome: str
    inconsistencias: List[InconsistenciaItem]

@app.get("/dashboard/qualidade-dados", response_model=List[QualidadeClinica])
async def dashboard_qualidade_dados():
    try:
        rows = supabase_get("vw_dashboard_final", select="*")
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao carregar dados do dashboard: {e}",
        )

    if not rows:
        return []

    df = to_df(rows)
    
    # --- Data Preparation ---
    df["mes_ref_date"] = pd.to_datetime(df.get("mes_ref_date", df.get("mes_ref")), errors="coerce")
    
    numeric_cols = [
        "valor_total_emitido", "taxa_pago_no_vencimento", "taxa_inadimplencia",
        "tempo_medio_pagamento_dias", "parc_media_parcelas_pond", "valor_medio_boleto"
    ]
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # --- Analysis ---
    all_inconsistencias = []
    
    # Ignore current month for consistency with main dashboard
    hoje_utc = datetime.utcnow()
    primeiro_dia_mes_atual = hoje_utc.replace(day=1, hour=0, minute=0, second=0, microsecond=0).date()
    df_filtered = df[df["mes_ref_date"].dt.date < primeiro_dia_mes_atual].copy()
    
    clinicas = df_filtered[["clinica_id", "clinica_nome"]].drop_duplicates().dropna()

    for _, clinica_row in clinicas.iterrows():
        clinica_id = clinica_row["clinica_id"]
        clinica_nome = clinica_row["clinica_nome"]
        
        clinic_df = df_filtered[df_filtered["clinica_id"] == clinica_id].copy()
        clinic_df = clinic_df.sort_values("mes_ref_date")
        
        inconsistencias = []

        # 1. Missing Month Detection
        if not clinic_df.empty and "mes_ref_date" in clinic_df.columns:
            clinic_df_dates = clinic_df.dropna(subset=["mes_ref_date"])
            if not clinic_df_dates.empty:
                min_date = clinic_df_dates['mes_ref_date'].min()
                max_date = clinic_df_dates['mes_ref_date'].max()
                
                if pd.notna(min_date) and pd.notna(max_date) and min_date != max_date:
                    expected_months = pd.date_range(start=min_date, end=max_date, freq='MS')
                    actual_months = pd.to_datetime(clinic_df_dates['mes_ref_date'].unique())
                    missing = sorted(list(set(expected_months) - set(actual_months)))
                    
                    for month in missing:
                        inconsistencias.append({
                            "tipo": "M√™s Faltante",
                            "detalhe": f"N√£o h√° dados para o m√™s {month.strftime('%Y-%m')} (per√≠odo de {min_date.strftime('%Y-%m')} a {max_date.strftime('%Y-%m')})."
                        })
        
        # 2. Strange Data Detection
        for _, row in clinic_df.iterrows():
            mes_str = _format_mes_ref(row.get("mes_ref_date"))
            
            # Taxa inadimplencia > 100%
            if "taxa_inadimplencia" in row and pd.notna(row["taxa_inadimplencia"]) and row["taxa_inadimplencia"] > 1:
                inconsistencias.append({
                    "tipo": "Valor Inv√°lido",
                    "mes_ref": mes_str,
                    "detalhe": f"Taxa de inadimpl√™ncia √© {row['taxa_inadimplencia']:.0%}, o que √© > 100%."
                })
            
            # Taxa pago no vencimento > 100%
            if "taxa_pago_no_vencimento" in row and pd.notna(row["taxa_pago_no_vencimento"]) and row["taxa_pago_no_vencimento"] > 1:
                inconsistencias.append({
                    "tipo": "Valor Inv√°lido",
                    "mes_ref": mes_str,
                    "detalhe": f"Taxa de pagamento no vencimento √© {row['taxa_pago_no_vencimento']:.0%}, o que √© > 100%."
                })
                
            # Negative values
            for col in ["valor_total_emitido", "tempo_medio_pagamento_dias"]:
                if col in row and pd.notna(row[col]) and row[col] < 0:
                     inconsistencias.append({
                        "tipo": "Valor Negativo",
                        "mes_ref": mes_str,
                        "detalhe": f"Coluna '{col}' possui valor negativo: {row[col]}."
                    })

        if inconsistencias:
            all_inconsistencias.append({
                "clinica_id": clinica_id,
                "clinica_nome": clinica_nome,
                "inconsistencias": inconsistencias
            })
            
    return all_inconsistencias


# ==========================
# NEW EXPORT LOGIC
# ==========================

class ExportPayload(BaseModel):
    columns: List[str]
    months: List[str]
    view_type: str
    clinica_ids: List[str]

async def _generate_export_df(payload: ExportPayload) -> pd.DataFrame:
    # 1. Fetch all data
    try:
        rows = supabase_get("vw_dashboard_final", select="*")
        if not rows:
            return pd.DataFrame()
        df = to_df(rows)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao carregar dados: {e}")

    # 2. Basic cleaning and type conversion
    df["mes_ref_date"] = pd.to_datetime(df.get("mes_ref_date", df.get("mes_ref")), errors="coerce")
    numeric_cols = [
        "valor_total_emitido", "taxa_pago_no_vencimento", "taxa_inadimplencia",
        "tempo_medio_pagamento_dias", "parc_media_parcelas_pond", "valor_medio_boleto",
        "score_ajustado", "limite_aprovado", "limite_sugerido"
    ]
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
            
    # --- Add calculated columns that might be requested ---
    df["taxa_pago_no_vencimento"] = df["taxa_pago_no_vencimento"].clip(0, 1)
    df["taxa_inad_dos_atrasados"] = df["taxa_inadimplencia"].clip(0, 1)
    df["valor_nao_pago_no_venc"] = df["valor_total_emitido"] * (1 - df["taxa_pago_no_vencimento"])
    df["valor_inad_real"] = df["valor_nao_pago_no_venc"] * df["taxa_inad_dos_atrasados"]
    df["taxa_inadimplencia_real"] = (df["valor_inad_real"] / df["valor_total_emitido"]).where(df["valor_total_emitido"] > 0, 0)
    
    # Re-calculate score using the global function
    df["score_credito"] = df.apply(_calc_score_row, axis=1)
    df["categoria_risco"] = df["score_credito"].apply(_categoria_from_score)


    # 3. Filter by months
    if not payload.months:
        raise HTTPException(status_code=400, detail="A lista de meses n√£o pode estar vazia.")
    
    df["mes_ref"] = df["mes_ref_date"].dt.strftime('%Y-%m')
    df_filtered = df[df["mes_ref"].isin(payload.months)].copy()

    # 4. Filter by clinics
    if payload.clinica_ids: # If the list is not empty, filter
        df_filtered = df_filtered[df_filtered["clinica_id"].isin(payload.clinica_ids)]

    if df_filtered.empty:
        return pd.DataFrame()

    # 5. Handle view type (aggregation)
    if payload.view_type == 'consolidado':
        agg_funcs = {
            'valor_total_emitido': 'sum',
            'valor_inad_real': 'sum',
            'score_credito': 'mean',
            'limite_aprovado': 'last',
            'limite_sugerido': 'last',
            'tempo_medio_pagamento_dias': 'mean',
            'valor_medio_boleto': 'mean',
            'parc_media_parcelas_pond': 'mean',
        }
        
        valid_agg_funcs = {k: v for k, v in agg_funcs.items() if k in df_filtered.columns}
        
        # Sort by date to ensure 'last' takes the latest value
        df_filtered = df_filtered.sort_values('mes_ref_date')
        
        grouped = df_filtered.groupby(['clinica_id', 'clinica_nome', 'cnpj'], as_index=False)
        df_agg = grouped.agg(valid_agg_funcs)

        if 'valor_total_emitido' in df_agg and 'valor_inad_real' in df_agg:
             df_agg["taxa_inadimplencia_real"] = (df_agg["valor_inad_real"] / df_agg["valor_total_emitido"]).where(df_agg["valor_total_emitido"] > 0, 0)

        if 'categoria_risco' in payload.columns:
            latest_categoria = df_filtered.loc[df_filtered.groupby('clinica_id')['mes_ref_date'].idxmax()][['clinica_id', 'categoria_risco']]
            df_agg = pd.merge(df_agg, latest_categoria, on='clinica_id', how='left')

        df_final = df_agg
    else: # 'separado'
        df_final = df_filtered.sort_values(['clinica_nome', 'mes_ref_date'])

    # 6. Select final columns
    final_columns = [col for col in payload.columns if col in df_final.columns]
    df_to_return = df_final[final_columns]
    
    return df_to_return


@app.post("/export/preview", response_model=List[Dict[str, Any]])
async def export_preview(payload: ExportPayload):
    # The payload from frontend now has `view_type` instead of `type`
    df = await _generate_export_df(payload)
    if df.empty:
        return []
    df_sample = df.head(10)
    # Format numbers for better preview
    for col in df_sample.columns:
        if pd.api.types.is_numeric_dtype(df_sample[col]):
            df_sample[col] = df_sample[col].apply(lambda x: f"{x:,.2f}" if pd.notnull(x) else "")
    df_sample = df_sample.fillna("")
    return df_sample.to_dict(orient="records")


@app.post("/export-dashboard", response_class=StreamingResponse)
async def export_dashboard(payload: ExportPayload):
    df = await _generate_export_df(payload)

    if df.empty:
        raise HTTPException(status_code=404, detail="Nenhum dado encontrado para exportar com os filtros selecionados.")

    output = BytesIO()
    df.to_excel(output, index=False, sheet_name='Dados')
    output.seek(0)
    
    filename = f"relatorio_credito_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )